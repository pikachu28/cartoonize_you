{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "background-removal-OpenCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18Wo_dfuk41ZC050ir1Zl_FzAhNVAA4Dv",
      "authorship_tag": "ABX9TyN3PYH93zyBdKLpM95Z+v8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pikachu28/cartoonize_you/blob/main/background_removal_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwvk70N8Zn9h"
      },
      "source": [
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Apply the transformations needed\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Define the helper function\n",
        "def decode_segmap(image, source, nc=21):\n",
        "  \n",
        "  label_colors = np.array([(0, 0, 0),  # 0=background\n",
        "               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
        "               (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\n",
        "               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
        "               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n",
        "               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n",
        "               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n",
        "               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
        "               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n",
        "\n",
        "  r = np.zeros_like(image).astype(np.uint8)\n",
        "  g = np.zeros_like(image).astype(np.uint8)\n",
        "  b = np.zeros_like(image).astype(np.uint8)\n",
        "   \n",
        "\n",
        "  for l in range(0, nc):\n",
        "    idx = image == l\n",
        "    r[idx] = label_colors[l, 0]\n",
        "    g[idx] = label_colors[l, 1]\n",
        "    b[idx] = label_colors[l, 2]\n",
        "  \n",
        "  rgb = np.stack([r, g, b], axis=2)\n",
        "\n",
        "  # Load the foreground input image \n",
        "  foreground = cv2.imread(source)\n",
        "\n",
        "  # Change the color of foreground image to RGB \n",
        "  # and resize image to match shape of R-band in RGB output map\n",
        "  foreground = cv2.cvtColor(foreground, cv2.COLOR_BGR2RGB)\n",
        "  foreground = cv2.resize(foreground,(r.shape[1],r.shape[0]))\n",
        "\n",
        "  # Create a background array to hold white pixels\n",
        "  # with the same size as RGB output map\n",
        "  background = 255 * np.ones_like(rgb).astype(np.uint8)\n",
        "\n",
        "  # Convert uint8 to float\n",
        "  foreground = foreground.astype(float)\n",
        "  background = background.astype(float)\n",
        "\n",
        "  # Create a binary mask of the RGB output map using the threshold value 0\n",
        "  th, alpha = cv2.threshold(np.array(rgb),0,255, cv2.THRESH_BINARY)\n",
        "\n",
        "  # Apply a slight blur to the mask to soften edges\n",
        "  alpha = cv2.GaussianBlur(alpha, (7,7),0)\n",
        "\n",
        "  # Normalize the alpha mask to keep intensity between 0 and 1\n",
        "  alpha = alpha.astype(float)/255\n",
        "\n",
        "  # Multiply the foreground with the alpha matte\n",
        "  foreground = cv2.multiply(alpha, foreground)  \n",
        "  \n",
        "  # Multiply the background with ( 1 - alpha )\n",
        "  background = cv2.multiply(1.0 - alpha, background)  \n",
        "  \n",
        "  # Add the masked foreground and background\n",
        "  outImage = cv2.add(foreground, background)\n",
        "\n",
        "  # Return a normalized output image for display\n",
        "  return outImage/255\n",
        "\n",
        "def segment(net, path, show_orig=True):\n",
        "  img = Image.open(path)\n",
        "  if show_orig: plt.imshow(img); plt.axis('off'); plt.show()\n",
        "  # Comment the Resize and CenterCrop for better inference results\n",
        "  trf = T.Compose([T.Resize(450), \n",
        "                   #T.CenterCrop(224), \n",
        "                   T.ToTensor(), \n",
        "                   T.Normalize(mean = [0.485, 0.456, 0.406], \n",
        "                               std = [0.229, 0.224, 0.225])])\n",
        "  inp = trf(img).unsqueeze(0)\n",
        "  out = net(inp)['out']\n",
        "  om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n",
        "  \n",
        "  rgb = decode_segmap(om, path)\n",
        "    \n",
        "  plt.imshow(rgb); plt.axis('off'); plt.show()\n",
        "  \n",
        "dlab = models.segmentation.deeplabv3_resnet101(pretrained=1).eval()\n",
        "\n",
        "image_path =  input(\"Enter the path of the image (Kindly take care of directories)\")\n",
        "segment(dlab, image_path, show_orig=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfmFSVWQhGkz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}